<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>GIE-Bench: Grounded Evaluation for Text-Guided Image Editing</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: "Helvetica Neue", sans-serif;
      margin: 0;
      padding: 0;
      background: #f8f9fa;
      color: #333;
    }
    header {
      background-color: #343a40;
      color: white;
      padding: 2rem 1rem;
      text-align: center;
    }
    header h1 {
      margin: 0;
      font-size: 2.5rem;
    }
    header p {
      margin-top: 0.5rem;
      font-size: 1.2rem;
    }
    .container {
      max-width: 960px;
      margin: 2rem auto;
      padding: 0 1rem;
    }
    section {
      margin-bottom: 2.5rem;
    }
    h2 {
      color: #212529;
      border-bottom: 2px solid #dee2e6;
      padding-bottom: 0.5rem;
    }
    ul {
      padding-left: 1.5rem;
    }
    img {
      max-width: 100%;
      border: 1px solid #ccc;
      border-radius: 8px;
      margin: 1rem 0;
    }
    footer {
      text-align: center;
      padding: 2rem 1rem;
      font-size: 0.9rem;
      color: #6c757d;
      border-top: 1px solid #dee2e6;
    }
    a {
      color: #007bff;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .buttons a {
      display: inline-block;
      margin: 0.5rem;
      padding: 0.6rem 1.2rem;
      background-color: #007bff;
      color: white;
      border-radius: 5px;
      text-decoration: none;
    }
    .buttons a:hover {
      background-color: #0056b3;
    }
  </style>
</head>
<body>

<header>
  <h1>GIE-Bench</h1>
  <p>Grounded Image Editing Evaluation Benchmark</p>
  <div class="buttons">
    <a href="https://arxiv.org/abs/2505.11493" target="_blank">üìÑ Paper</a>
    <a href="https://github.com/yourusername/GIE-Bench" target="_blank">üíª GitHub</a>
    <a href="#" target="_blank">‚¨áÔ∏è Dataset (Coming Soon)</a>
  </div>
</header>

<div class="container">

  <section>
    <h2>Overview</h2>
    <p>
      GIE-Bench is a benchmark for evaluating <strong>text-guided image editing</strong> models in a grounded and interpretable way.
      It assesses both:
    </p>
    <ul>
      <li><strong>Functional correctness</strong> using VQA-style multiple-choice questions</li>
      <li><strong>Content preservation</strong> using object-aware masking and similarity metrics</li>
    </ul>
    <p>
      It includes over <strong>1,000 curated editing examples</strong> across 20 image domains and 9 edit types.
    </p>
  </section>

  <section>
    <h2>Evaluation Pipeline</h2>
    <img src="sample_pipeline.png" alt="GIE-Bench Pipeline Overview">
    <p style="font-style: italic;">Figure: Functional correctness and content preservation modules in GIE-Bench.</p>
  </section>

  <section>
    <h2>Key Features</h2>
    <ul>
      <li>Automatic, scalable evaluation with VQA-style questions</li>
      <li>Object-aware mask-based preservation metrics</li>
      <li>Supports 9 types of edits: object add/remove, size, background, layout, etc.</li>
      <li>Comparison across state-of-the-art editing models including GPT-Image-1, MGIE, OmniGen</li>
    </ul>
  </section>

  <section>
    <h2>Examples</h2>
    <img src="example_edit.png" alt="Example Edits">
    <p><strong>Instruction:</strong> Replace the boat on the canal with a gondola.<br>
       <strong>Question:</strong> What type of watercraft is present on the canal?<br>
       <strong>Answer:</strong> Gondola</p>
  </section>

  <section>
    <h2>Get Involved</h2>
    <p>
      We welcome contributions and collaborations! Stay tuned for:
    </p>
    <ul>
      <li>Dataset and evaluation code release</li>
      <li>Leaderboard of editing model performance</li>
      <li>Extension to multi-turn editing and compositional tasks</li>
    </ul>
  </section>

</div>

<footer>
  &copy; 2025 Yusu Qian and collaborators. Hosted on GitHub Pages.
</footer>

</body>
</html>
